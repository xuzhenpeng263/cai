"""
Basic utilities for executing tools
inside or outside of virtual containers.
"""

import subprocess  # nosec B404
import threading
import os
import pty
import signal
import time
import uuid
import sys
import shlex
from wasabi import color  # pylint: disable=import-error
from cai.util import format_time, start_active_timer, stop_active_timer, start_idle_timer, stop_idle_timer, cli_print_tool_output


# Instead of direct import
try:
    from cai.cli import START_TIME
except ImportError:
    START_TIME = None

# Global dictionary to store active sessions
ACTIVE_SESSIONS = {}

# Global counter for session output commands to ensure they always display
SESSION_OUTPUT_COUNTER = {}

def _get_workspace_dir() -> str:
    """Determines the target workspace directory based on env vars for host."""
    base_dir_env = os.getenv("CAI_WORKSPACE_DIR")
    workspace_name = os.getenv("CAI_WORKSPACE")

    # Determine the base directory
    if base_dir_env:
        base_dir = os.path.abspath(base_dir_env)
    else: # Default base directory is 'workspaces' 
        if workspace_name:
            base_dir = os.path.join(os.getcwd(), "workspaces")
        else: # If no workspace name is set, the workspace IS the CWD.
             return os.getcwd()

    # If a workspace name is provided, append it to the base directory
    if workspace_name:
        if not all(c.isalnum() or c in ['_', '-'] for c in workspace_name):
            print(color(f"Invalid CAI_WORKSPACE name '{workspace_name}'. "
                        f"Using directory '{base_dir}' instead.", fg="yellow"))
            target_dir = base_dir
        else:
             target_dir = os.path.join(base_dir, workspace_name)
    else:
         target_dir = base_dir

    # Ensure the final target directory exists on the host
    try:
        abs_target_dir = os.path.abspath(target_dir)
        os.makedirs(abs_target_dir, exist_ok=True)
        return abs_target_dir
    except OSError as e:
        print(color(f"Error creating/accessing host workspace directory '{abs_target_dir}': {e}",
                    fg="red"))
        print(color(f"Falling back to current directory: {os.getcwd()}", fg="yellow"))
        return os.getcwd()

def _get_container_workspace_path() -> str:
    """Determines the target workspace path inside the container."""
    workspace_name = os.getenv("CAI_WORKSPACE") 
    if workspace_name:
        if not all(c.isalnum() or c in ['_', '-'] for c in workspace_name):
            print(color(f"Invalid CAI_WORKSPACE name '{workspace_name}' for container. "
                        f"Using '/workspace'.", fg="yellow"))
            return "/"
        # Standard path inside CAI containers
        return f"/workspace/workspaces/{workspace_name}"
    else:
        return "/"

class ShellSession:  # pylint: disable=too-many-instance-attributes
    """Class to manage interactive shell sessions"""

    def __init__(self, command, session_id=None, ctf=None, workspace_dir=None, container_id=None): # noqa E501
        self.session_id = session_id or str(uuid.uuid4())[:8]
        self.command = command  
        self.ctf = ctf
        self.container_id = container_id 
        # Determine workspace based on context (container, ctf or local host)
        if self.container_id:
            self.workspace_dir = _get_container_workspace_path()
        elif self.ctf:
            self.workspace_dir = workspace_dir or _get_workspace_dir()
        else:
            self.workspace_dir = _get_workspace_dir()
        self.process = None
        self.master = None
        self.slave = None
        self.output_buffer = []
        self.is_running = False
        self.last_activity = time.time()

    def start(self):
        """Start the shell session in the appropriate environment."""
        start_message_cmd = self.command 

        # --- Start in Container ---
        if self.container_id:
            try:
                self.master, self.slave = pty.openpty()
                docker_cmd_list = [
                    "docker", "exec", "-i",
                    "-w", self.workspace_dir, 
                    self.container_id,
                    "sh", "-c", # Use shell to handle complex commands if needed
                    self.command # The actual command to run
                ]
                self.process = subprocess.Popen(
                    docker_cmd_list,
                    stdin=self.slave,
                    stdout=self.slave,
                    stderr=self.slave,
                    preexec_fn=os.setsid,
                    universal_newlines=True
                )
                self.is_running = True
                self.output_buffer.append(
                    f"[Session {self.session_id}] Started in container {self.container_id[:12]}: "
                    f"{start_message_cmd} in {self.workspace_dir}")
                threading.Thread(target=self._read_output, daemon=True).start()
            except Exception as e:
                self.output_buffer.append(f"Error starting container session: {str(e)}")
                self.is_running = False
                return str(e)

        # --- Start in CTF ---
        if self.ctf:
            self.is_running = True
            self.output_buffer.append(
                f"[Session {self.session_id}] Started CTF command: {self.command}")
            try:
                output = self.ctf.get_shell(self.command)
                self.output_buffer.append(output)
            except Exception as e:  # pylint: disable=broad-except
                self.output_buffer.append(f"Error executing CTF command: {str(e)}")
                self.is_running = False 
                return str(e)

        # --- Start Locally (Host) ---
        try:
            self.master, self.slave = pty.openpty()
            self.process = subprocess.Popen(  # pylint: disable=subprocess-popen-preexec-fn, consider-using-with # noqa: E501
                self.command, 
                shell=True,  # nosec B602 
                stdin=self.slave,
                stdout=self.slave,
                stderr=self.slave,
                cwd=self.workspace_dir, 
                preexec_fn=os.setsid,
                universal_newlines=True
            )
            self.is_running = True
            self.output_buffer.append(
                f"[Session {self.session_id}] Started: {self.command}")
            # Start a thread to read output
            threading.Thread(target=self._read_output, daemon=True).start()
        except Exception as e:  # pylint: disable=broad-except
            self.output_buffer.append(f"Error starting local session: {str(e)}")
            self.is_running = False
            return str(e)
    def _read_output(self):
        """Read output from the process"""
        try:
            # Buffer for incomplete lines
            partial_line = ""
            
            while self.is_running and self.master is not None:
                try:
                    # Check if process has exited before reading
                    if self.process and self.process.poll() is not None:
                        self.is_running = False
                        break
                    
                    # Read the output - increased buffer size to avoid cutting commands
                    output = os.read(self.master, 4096).decode('utf-8', errors='replace')
                    
                    if output:
                        # Combine with any partial line from previous read
                        full_output = partial_line + output
                        
                        # Split into lines but keep the last partial line if it doesn't end with newline
                        lines = full_output.split('\n')
                        
                        # If output doesn't end with newline, the last item is a partial line
                        if not output.endswith('\n'):
                            partial_line = lines[-1]
                            lines = lines[:-1]
                        else:
                            partial_line = ""
                        
                        # Add complete lines to buffer
                        for line in lines:
                            if line:  # Don't add empty lines
                                self.output_buffer.append(line)
                        
                        self.last_activity = time.time()
                    else:
                        # os.read() returned empty. This does NOT necessarily mean
                        # the process itself has exited if self.process.poll() is None.
                        # It might be idle and waiting for input.
                        if self.process and self.process.poll() is None:
                            # Process is alive but PTY read was empty (e.g., idle).
                            pass
                        else:
                            # Process is confirmed dead or no process to check,
                            # and read returned empty. Session is over.
                            if partial_line:
                                # Add any remaining partial line
                                self.output_buffer.append(partial_line)
                            self.is_running = False
                            break
                except UnicodeDecodeError as e:
                    # Handle unicode decode errors gracefully
                    self.output_buffer.append(f"[Session {self.session_id}] Unicode decode error in output")
                    continue
                except Exception as read_err: 
                    self.output_buffer.append(f"Error reading output buffer: {str(read_err)}")
                    self.is_running = False
                    break
                    
                # Add a small sleep to prevent busy-waiting if no output
                if self.is_process_running():
                    time.sleep(0.05)
                    
        except Exception as e:
            self.output_buffer.append(f"Error in read_output loop: {str(e)}")
            self.is_running = False
            return str(e)
    

    def is_process_running(self):
        """Check if the process is still running"""
        # For CTF or container
        if self.container_id or self.ctf: 
            return self.is_running
        # For local host
        if not self.process:
            return False
        return self.process.poll() is None

    def send_input(self, input_data):
        """Send input to the process (local or container)"""
        if not self.is_running: # For CTF or container
            if self.process and self.process.poll() is None:
                self.is_running = True 
            else:  # For local host
                 return "Session is not running"

        try:
            # --- Send to CTF ---
            if self.ctf:
                output = self.ctf.get_shell(input_data)
                self.output_buffer.append(output)
                return "Input sent to CTF session"

            # --- Send to Local or Container PTY ---
            if self.master is not None:
                input_data_bytes = (input_data.rstrip() + "\n").encode()
                bytes_written = os.write(self.master, input_data_bytes)
                if bytes_written != len(input_data_bytes):
                     self.output_buffer.append(f"[Session {self.session_id}] Warning: Partial input write.")
                self.last_activity = time.time()
                return "Input sent to session"
            else:
                return "Session PTY not available for input"
        except Exception as e:  # pylint: disable=broad-except
            self.output_buffer.append(f"Error sending input: {str(e)}")
            return f"Error sending input: {str(e)}"

    def get_output(self, clear=True):
        """Get and optionally clear the output buffer"""
        output = "\n".join(self.output_buffer)
        if clear:
            self.output_buffer = []
        return output
    
    def get_new_output(self, mark_position=True):
        """Get only new output since last marked position"""
        if not hasattr(self, '_last_output_position'):
            self._last_output_position = 0
        
        # Get new output since last position
        new_output_lines = self.output_buffer[self._last_output_position:]
        new_output = "\n".join(new_output_lines)
        
        # Update position marker if requested
        if mark_position:
            self._last_output_position = len(self.output_buffer)
        
        return new_output

    def terminate(self):
        """Terminate the session"""
        session_id_short = self.session_id[:8]
        termination_message = f"Session {session_id_short} terminated"
        
        if not self.is_running:
             if self.process and self.process.poll() is None:
                 pass # Process is running, proceed with termination
             else:
                 return f"Session {session_id_short} already terminated or finished."

        try:
            self.is_running = False

            if self.process:
                # Try to terminate the process group
                try:
                    pgid = os.getpgid(self.process.pid)
                    os.killpg(pgid, signal.SIGTERM) 
                except ProcessLookupError:
                     pass # Process already gone
                except subprocess.TimeoutExpired:
                     print(color(f"Session {session_id_short} did not terminate gracefully, sending SIGKILL...", fg="yellow")) # noqa E501
                     try:
                          if pgid:
                              os.killpg(pgid, signal.SIGKILL) # Force kill
                          else:
                              self.process.kill()
                     except ProcessLookupError:
                          pass # Already gone
                     except Exception as kill_err:
                          termination_message = f" (Error during SIGKILL: {kill_err})"
                except Exception as term_err: # Catch other errors during SIGTERM
                     termination_message = f" (Error during SIGTERM: {term_err})"
                     try:
                         self.process.kill()
                     except Exception: pass # Ignore nested errors


                # Final check
                if self.process.poll() is None:
                     print(color(f"Session {session_id_short} process {self.process.pid} may still be running after termination attempts.", fg="red")) # noqa E501
                     termination_message += " (Warning: Process may still be running)"


            # Clean up PTY resources if they exist
            if self.master:
                try: os.close(self.master)
                except OSError: pass
                self.master = None
            if self.slave:
                try: os.close(self.slave)
                except OSError: pass
                self.slave = None
                
            return termination_message
        except Exception as e:  # pylint: disable=broad-except
            return f"Error terminating session {session_id_short}: {str(e)}"


def create_shell_session(command, ctf=None, container_id=None, **kwargs):
    """Create a new shell session in the correct workspace/environment."""
    if container_id:
        session = ShellSession(command, ctf=ctf, container_id=container_id)
    else:
        workspace_dir = _get_workspace_dir()
        session = ShellSession(command, ctf=ctf, workspace_dir=workspace_dir)

    session.start()
    if session.is_running or (ctf and not session.is_running): 
         ACTIVE_SESSIONS[session.session_id] = session
         return session.session_id
    else:
         error_msg = session.get_output(clear=True)
         print(color(f"Failed to start session: {error_msg}", fg="red"))
         return f"Failed to start session: {error_msg}"


def list_shell_sessions():
    """List all active shell sessions"""
    result = []
    for session_id, session in list(ACTIVE_SESSIONS.items()):
        # Clean up terminated sessions
        if not session.is_running:
            del ACTIVE_SESSIONS[session_id]
            continue

        result.append({
            "session_id": session_id,
            "command": session.command,
            "running": session.is_running,
            "last_activity": time.strftime(
                "%H:%M:%S",
                time.localtime(session.last_activity))
        })
    return result


def send_to_session(session_id, input_data):
    """Send input to a specific session"""
    if session_id not in ACTIVE_SESSIONS:
        return f"Session {session_id} not found"

    session = ACTIVE_SESSIONS[session_id]
    return session.send_input(input_data)


def get_session_output(session_id, clear=True, stdout=True):
    """Get output from a specific session"""
    if session_id not in ACTIVE_SESSIONS:
        return f"Session {session_id} not found"

    session = ACTIVE_SESSIONS[session_id]
    output = session.get_output(clear)
    
    return output


def terminate_session(session_id):
    """Terminate a specific session"""
    if session_id not in ACTIVE_SESSIONS:
        return f"Session {session_id} not found or already terminated."

    session = ACTIVE_SESSIONS[session_id]
    result = session.terminate()
    if session_id in ACTIVE_SESSIONS:
        del ACTIVE_SESSIONS[session_id]
    return result


def _run_ctf(ctf, command, stdout=False, timeout=100, workspace_dir=None, stream=False):
    """Runs command in CTF env, changing to workspace_dir first."""
    target_dir = workspace_dir or _get_workspace_dir()
    full_command = f"{command}"
    original_cmd_for_msg = command # For logging
    context_msg = f"(ctf:{target_dir})"
    try:
        output = ctf.get_shell(full_command, timeout=timeout)
        # In streaming mode, don't print to stdout to avoid duplication
        # The streaming system will handle the display
        if stdout and not stream:
            print(f"\033[32m{context_msg} $ {original_cmd_for_msg}\n{output}\033[0m") # noqa E501
        return output
    except Exception as e:  # pylint: disable=broad-except
        error_msg = f"Error executing CTF command '{original_cmd_for_msg}' in '{target_dir}': {e}" # noqa E501
        print(color(error_msg, fg="red"))
        return error_msg

def _run_ssh(command, stdout=False, timeout=100, workspace_dir=None, stream=False):
    """Runs command via SSH. Assumes SSH agent or passwordless setup unless sshpass is used externally.""" # noqa E501
    ssh_user = os.environ.get('SSH_USER')
    ssh_host = os.environ.get('SSH_HOST')
    ssh_pass = os.environ.get('SSH_PASS') 
    remote_command = command
    original_cmd_for_msg = command
    context_msg = f"({ssh_user}@{ssh_host})"

    # Construct base SSH command list
    if ssh_pass:
        ssh_cmd_list = ["sshpass", "-p", ssh_pass, "ssh", f"{ssh_user}@{ssh_host}"] # noqa E501
    else:
        ssh_cmd_list = ["ssh", f"{ssh_user}@{ssh_host}"]
    ssh_cmd_list.append(remote_command)

    try:
        # Use subprocess.run with list of args for better security than shell=True
        result = subprocess.run(
            ssh_cmd_list,
            capture_output=True,
            text=True,
            check=False, # Don't raise exception on non-zero exit code
            timeout=timeout
        )
        output = result.stdout if result.stdout else result.stderr
        # In streaming mode, don't print to stdout to avoid duplication
        # The streaming system will handle the display
        if stdout and not stream:
            print(f"\033[32m{context_msg} $ {original_cmd_for_msg}\n{output}\033[0m") # noqa E501
        # Return combined output, potentially including errors
        return output.strip()
    except subprocess.TimeoutExpired as e:
        error_output = e.stdout if e.stdout else str(e)
        timeout_msg = f"Timeout executing SSH command: {error_output}"
        if stdout and not stream:
            print(f"\033[33m{context_msg} $ {original_cmd_for_msg}\nTIMEOUT\n{error_output}\033[0m") # noqa E501
        return timeout_msg
    except FileNotFoundError:
         # Handle case where ssh or sshpass isn't installed
         error_msg = f"'sshpass' or 'ssh' command not found. Ensure they are installed and in PATH." # noqa E501
         print(color(error_msg, fg="red"))
         return error_msg
    except Exception as e:  # pylint: disable=broad-except
        error_msg = f"Error executing SSH command '{original_cmd_for_msg}' on {ssh_host}: {e}" # noqa E501
        print(color(error_msg, fg="red"))
        return error_msg


def _run_local(command, stdout=False, timeout=100, stream=False, call_id=None, tool_name=None, workspace_dir=None, custom_args=None):
    """Runs command locally in the specified workspace_dir."""
    # Make sure we're in active time mode for tool execution
    stop_idle_timer()
    start_active_timer()
    
    process_start_time = time.time()  # Initialize with current time
    try:
        target_dir = workspace_dir or _get_workspace_dir()
        original_cmd_for_msg = command # For logging
        context_msg = f"(local:{target_dir})"
        
        # If streaming is enabled and we have a call_id
        if stream:
            # Import the streaming utilities from util
            from cai.util import start_tool_streaming, update_tool_streaming, finish_tool_streaming
            
            # Parse command into parts for display
            parts = command.strip().split(' ', 1)
            cmd_var = parts[0] if parts else ""
            args_param_val = parts[1] if len(parts) > 1 else "" # Renamed to avoid conflict with tool_args dict key
            
            # For generic Linux commands, standardize the tool_name format
            if not tool_name:
                tool_name = f"{cmd_var}_command" if cmd_var else "command"
            
            # Create args dictionary with non-empty values only
            tool_args = {}
            if cmd_var:
                tool_args["command"] = cmd_var
            if args_param_val and args_param_val.strip():
                tool_args["args"] = args_param_val
            
            # Add more context for the command
            tool_args["workspace"] = os.path.basename(target_dir)
            tool_args["full_command"] = command
            
            # If custom args were provided, merge them with the default args
            if custom_args is not None:
                if isinstance(custom_args, dict):
                    # Merge the dictionaries, with custom args taking precedence
                    for key, value in custom_args.items():
                        tool_args[key] = value
            
            # For generic commands, ensure we have a unique call_id
            if not call_id:
                call_id = f"cmd_{cmd_var}_{str(uuid.uuid4())[:8]}"
            
            # Initialize/use the call_id for this streaming session
            call_id = start_tool_streaming(tool_name, tool_args, call_id)
            
            # Start the process
            process = subprocess.Popen(
                command,
                shell=True,  # nosec B602
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                cwd=target_dir
            )
            
            # Begin collecting output
            output_buffer = []
            buffer_size = 0
            update_interval = 10  # lines - default for most tools
            
            # Use a smaller interval for generic_linux_command for better responsiveness
            if tool_name == "generic_linux_command":
                update_interval = 3  # Update more frequently for terminal commands
                
                # Add refresh rate info to tool_args for cli_print_tool_output
                if "refresh_rate" not in tool_args:
                    tool_args["refresh_rate"] = 2
            
            # Stream stdout in real-time
            for line in iter(process.stdout.readline, ''):
                if not line:
                    break
                
                # Add to output collection
                output_buffer.append(line)
                buffer_size += 1
                
                # Only update periodically to reduce UI refreshes
                if buffer_size >= update_interval:
                    current_output = ''.join(output_buffer)
                    update_tool_streaming(tool_name, tool_args, current_output, call_id)
                    buffer_size = 0
            
            # Finish process
            process.stdout.close()
            return_code = process.wait(timeout=timeout)
            process_execution_time = time.time() - process_start_time
            
            # Get any stderr output
            stderr_data = process.stderr.read()
            if stderr_data:
                output_buffer.append("\nERROR OUTPUT:\n" + stderr_data)
            
            # Final output update
            final_output = ''.join(output_buffer)
            if return_code != 0:
                final_output += f"\nCommand exited with code {return_code}"
                
            # Calculate execution info with environment details
            execution_info = {
                "status": "completed" if return_code == 0 else "error",
                "return_code": return_code,
                "environment": "Local",
                "host": os.path.basename(target_dir),
                "tool_time": process_execution_time
            }
            
            # Complete the streaming session with final output
            finish_tool_streaming(tool_name, tool_args, final_output, call_id, execution_info)
            
            return final_output
        else:
            # Standard non-streaming execution
            result = subprocess.run(
                command,
                shell=True,  # nosec B602
                capture_output=True,
                text=True,
                check=False, 
                timeout=timeout,
                cwd=target_dir 
            )
            output = result.stdout if result.stdout else result.stderr
            
            # In non-streaming mode, we should NOT display the output via cli_print_tool_output
            # to avoid duplication. The output will be handled by the calling function.
            # Only return the raw output for the calling function to handle.
            return output.strip()
    except subprocess.TimeoutExpired as e:
        error_output = e.stdout if hasattr(e, 'stdout') and e.stdout else str(e)
        error_msg = f"Command timed out after {timeout} seconds\n{error_output}"
        
        # If we're streaming, show the timeout in the tool output panel
        if stream and call_id:
            from cai.util import finish_tool_streaming
            # Parse the command the same way we did for streaming
            parts = command.strip().split(' ', 1)
            cmd_var = parts[0] if parts else ""
            args_var = parts[1] if len(parts) > 1 else ""
            
            # Ensure tool_args has complete information
            tool_args = {
                "command": cmd_var,
                "args": args_var if args_var.strip() else "",
                "full_command": command,
                "environment": "Local",
                "workspace": os.path.basename(target_dir)
            }
            execution_info = {
                "status": "timeout", 
                "error": str(e),
                "environment": "Local",
                "host": os.path.basename(target_dir)
            }
            finish_tool_streaming(tool_name or f"{cmd_var}_command", tool_args, error_msg, call_id, execution_info)
            
        if stdout:
            print("\033[32m" + error_msg + "\033[0m")
            return error_msg

            
        return error_msg
    except Exception as e:  # pylint: disable=broad-except
        error_msg = f"Error executing local command: {e}"
        
        # If we're streaming, show the error in the tool output panel
        if stream and call_id:
            from cai.util import finish_tool_streaming
            # Parse the command the same way we did for streaming
            parts = command.strip().split(' ', 1)
            cmd_var = parts[0] if parts else ""
            args_var = parts[1] if len(parts) > 1 else ""
            
            # Ensure tool_args has complete information
            tool_args = {
                "command": cmd_var,
                "args": args_var if args_var.strip() else "",
                "full_command": command,
                "environment": "Local",
                "workspace": os.path.basename(target_dir)
            }
            execution_info = {
                "status": "error", 
                "error": str(e),
                "environment": "Local",
                "host": os.path.basename(target_dir)
            }
            finish_tool_streaming(tool_name or f"{cmd_var}_command", tool_args, error_msg, call_id, execution_info)
            
        print(color(error_msg, fg="red"))
        return error_msg
    finally:
        # Always switch back to idle mode when function completes
        stop_active_timer()
        start_idle_timer()


def run_command(command, ctf=None, stdout=False,  # pylint: disable=too-many-arguments # noqa: E501
                async_mode=False, session_id=None,
                timeout=100, stream=False, call_id=None, tool_name=None, args=None):
    """
    Run command in the appropriate environment (Docker, CTF, SSH, Local)
    and workspace.

    Args:
        command: The command to execute
        ctf: CTF environment object (if running in CTF)
        stdout: Whether to print output to stdout
        async_mode: Whether to run the command asynchronously
        session_id: ID of an existing session to send the command to
        timeout: Command timeout in seconds
        stream: Whether to stream output in real-time
        call_id: Unique ID for the command execution (for streaming)
        tool_name: Name of the tool being executed (for display in streaming output).
                  If None, the tool name will be derived from the command.
        args: Additional arguments for the tool (for display and context).

    Returns:
        str: Command output, status message, or session ID.
    """
    if ctf and not hasattr(ctf, "get_shell"):
        ctf = None
    # Use the active timer during tool execution
    stop_idle_timer()
    start_active_timer()
 
    from cai.cli import ctf_global
    ctf = ctf_global
    
    # Parse command into standard parts to ensure consistent naming
    parts = command.strip().split(' ', 1)
    cmd_name = parts[0] if parts else ""
    cmd_args = parts[1] if len(parts) > 1 else ""
    
    # Generate a call_id if we're streaming and one wasn't provided
    # Use a more specific format that includes the command name for easier tracking
    if not call_id and stream:
        call_id = f"cmd_{cmd_name}_{str(uuid.uuid4())[:8]}"
        
    # If no tool_name is provided, derive it from the command in a consistent way
    if not tool_name:
        tool_name = f"{cmd_name}_command" if cmd_name else "command"
    
    try:
        # If session_id is provided, send command to that session
        if session_id:
            if session_id not in ACTIVE_SESSIONS:
                # Switch back to idle mode before returning error
                stop_active_timer()
                start_idle_timer()
                return f"Session {session_id} not found"
            session = ACTIVE_SESSIONS[session_id]
            result = session.send_input(command) # Send the raw command string
            
            # Wait for the command to execute and capture output
            # This provides automatic output display for async sessions
            wait_time = 3.0  # Wait 3 seconds for command to execute
            
            # Mark the current position in the output buffer before sending input
            session.get_new_output(mark_position=True)  # Reset position marker
            
            # Smart waiting: check for new output every 0.5 seconds, up to max wait time
            max_wait = wait_time
            check_interval = 0.5
            elapsed = 0.0
            new_output_detected = False
            
            while elapsed < max_wait:
                time.sleep(check_interval)
                elapsed += check_interval
                
                # Check if new output is available
                current_new_output = session.get_new_output(mark_position=False)
                
                # If we detect new output, wait a bit more for it to complete, then break
                if current_new_output.strip():
                    if not new_output_detected:
                        new_output_detected = True
                        # Give it a bit more time to complete the output
                        time.sleep(0.5)
                    else:
                        # We already detected new output and waited, now break
                        break
            
            # Always show the session output after sending input using the counter mechanism
            # Generate unique counter for this session input command
            counter_key = f"session_input_{session_id}"
            if counter_key not in SESSION_OUTPUT_COUNTER:
                SESSION_OUTPUT_COUNTER[counter_key] = 0
            SESSION_OUTPUT_COUNTER[counter_key] += 1
            
            # Create args for display
            session_args = {
                "command": command,
                "args": "",
                "session_id": session_id,
                "call_counter": SESSION_OUTPUT_COUNTER[counter_key],  # This ensures uniqueness
                "input_to_session": True,  # Flag to identify this as session input
            }
            
            # Only add auto_output if not already present (prevents duplication)
            if args and isinstance(args, dict):
                # If args were passed and contain auto_output, use that value
                if "auto_output" in args:
                    session_args["auto_output"] = args["auto_output"]
                else:
                    # Otherwise, force it to True for session commands
                    session_args["auto_output"] = True
            else:
                # No args provided, force auto_output
                session_args["auto_output"] = True
            
            # Determine environment info for display
            env_type = "Local"
            if session.container_id:
                env_type = f"Container({session.container_id[:12]})"
            elif session.ctf:
                env_type = "CTF"
            
            # Get only the NEW output to display (not the entire buffer)
            output = session.get_new_output(mark_position=True)
            
            # Create execution info
            execution_info = {
                "status": "completed",
                "environment": env_type,
                "host": session.workspace_dir,
                "session_id": session_id,
                "wait_time": elapsed,
                "new_output_detected": new_output_detected
            }
            
            # Display the session input and its result using cli_print_tool_output
            from cai.util import cli_print_tool_output
            cli_print_tool_output(
                tool_name="generic_linux_command",
                args=session_args,
                output=output,
                execution_info=execution_info,
                streaming=False
            )
            
            # For async sessions, we don't switch back to idle mode here
            # since the session continues to run in the background
            if not async_mode:
                # Switch back to idle mode after synchronous command completes
                stop_active_timer()
                start_idle_timer()
                
            # Return the actual output from the session
            # The output has already been displayed via cli_print_tool_output
            if output and output.strip():
                return output
            else:
                return f"Command sent to session {session_id}. No output captured."

        # 2. Determine Execution Environment (Container > CTF > SSH > Local)
        active_container = os.getenv("CAI_ACTIVE_CONTAINER", "")
        is_ssh_env = all(os.getenv(var) for var in ['SSH_USER', 'SSH_HOST'])

        # --- Docker Container Execution ---
        if active_container and not is_ssh_env:
            container_id = active_container
            container_workspace = _get_container_workspace_path()
            context_msg = f"(docker:{container_id[:12]}:{container_workspace})"

            # Handle Async Session Creation in Container
            # Only create new session if no session_id is provided
            if async_mode and not session_id:
                # Create a session specifically for the container environment
                new_session_id = create_shell_session(command, container_id=container_id) # noqa E501
                if "Failed" in new_session_id: # Check if session creation failed
                    # Switch back to idle mode before returning error
                    stop_active_timer()
                    start_idle_timer()
                    return new_session_id
                
                # Display the command that creates the async session
                from cai.util import cli_print_tool_output
                
                # Create args for display
                session_creation_args = {
                    "command": command,
                    "args": "",
                    "session_id": new_session_id,
                    "async_mode": True
                }
                
                # Create execution info
                execution_info = {
                    "status": "session_created",
                    "environment": f"Container({container_id[:12]})",
                    "host": container_workspace,
                    "session_id": new_session_id
                }
                
                # Get initial output if any
                session = ACTIVE_SESSIONS.get(new_session_id)
                initial_output = ""
                if session:
                    time.sleep(0.2)  # Wait a moment for initial output
                    initial_output = session.get_new_output(mark_position=True)
                
                # Format the output message
                output_msg = f"Started async session {new_session_id} in container {container_id[:12]}. Use this ID to interact."
                if initial_output:
                    output_msg += f"\n\n{initial_output}"
                
                # Display the session creation command and initial output
                cli_print_tool_output(
                    tool_name="generic_linux_command",
                    args=session_creation_args,
                    output=output_msg,
                    execution_info=execution_info,
                    streaming=False
                )
                
                # For async sessions, switch back to idle mode after session creation
                stop_active_timer()
                start_idle_timer()
                return f"Started async session {new_session_id} in container {container_id[:12]}. Use this ID to interact." # noqa E501

            # Handle Streaming Container Execution
            if stream:
                # Import the streaming utilities from util
                from cai.util import start_tool_streaming, update_tool_streaming, finish_tool_streaming
                
                # Create args dictionary with standardized format
                tool_args = {
                    "command": cmd_name,
                    "args": cmd_args if cmd_args.strip() else "",
                    "full_command": command,
                    "container": container_id[:12],
                    "environment": "Container",
                    "workspace": container_workspace
                }
                
                # Add refresh rate info for generic_linux_command
                if tool_name == "generic_linux_command":
                    tool_args["refresh_rate"] = 2
                
                # Initialize the streaming session with a consistent call_id format
                call_id = start_tool_streaming(tool_name, tool_args, call_id)
                
                # Update with "executing" status
                update_tool_streaming(
                    tool_name,
                    tool_args,
                    f"Executing in container {container_id[:12]} at {container_workspace}:\n{command}\n\nPreparing environment...",
                    call_id
                )
                
                # Ensure workspace directory exists inside the container first
                mkdir_cmd = [
                    "docker", "exec", container_id,
                    "mkdir", "-p", container_workspace
                ]
                subprocess.run(
                    mkdir_cmd,
                    capture_output=True,
                    text=True,
                    check=False,
                    timeout=10
                )
                
                # Update status once environment is prepared
                update_tool_streaming(
                    tool_name,
                    tool_args,
                    f"Executing in container {container_id[:12]} at {container_workspace}:\n{command}\n\nRunning command...",
                    call_id
                )

                # Build docker exec command as a single shell string for streaming
                docker_exec_cmd = (
                    "docker exec -w "
                    f"{shlex.quote(container_workspace)} "
                    f"{shlex.quote(container_id)} sh -c "
                    f"{shlex.quote(command)}"
                )
                
                try:
                    start_time = time.time()
                    # Start the process
                    process = subprocess.Popen(
                        docker_exec_cmd,
                        shell=True,  # nosec B602
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True,
                        bufsize=1,
                        cwd=_get_workspace_dir()
                    )
                    
                    # Begin collecting output
                    output_buffer = []
                    buffer_size = 0
                    update_interval = 10  # lines
                    
                    # Stream stdout in real-time
                    for line in iter(process.stdout.readline, ''):
                        if not line:
                            break
                        
                        # Add to output collection
                        output_buffer.append(line)
                        buffer_size += 1
                        
                        # Only update periodically to reduce UI refreshes
                        if buffer_size >= update_interval:
                            current_output = ''.join(output_buffer)
                            update_tool_streaming(tool_name, tool_args, current_output, call_id)
                            buffer_size = 0
                    
                    # Finish process
                    process.stdout.close()
                    return_code = process.wait(timeout=timeout)
                    execution_time = time.time() - start_time
                    
                    # Get any stderr output
                    stderr_data = process.stderr.read()
                    if stderr_data:
                        output_buffer.append("\nERROR OUTPUT:\n" + stderr_data)
                    
                    # Final output update
                    final_output = ''.join(output_buffer)
                    if return_code != 0:
                        final_output += f"\nCommand exited with code {return_code}"
                    
                    # Calculate execution info
                    execution_info = {
                        "status": "completed" if return_code == 0 else "error",
                        "return_code": return_code,
                        "environment": "Container",
                        "host": container_id[:12],
                        "tool_time": execution_time
                    }
                    
                    # Complete the streaming session with final output
                    finish_tool_streaming(tool_name, tool_args, final_output, call_id, execution_info)
                    
                    # Switch back to idle mode after streaming command completes
                    stop_active_timer()
                    start_idle_timer()
                    return final_output
                
                except subprocess.TimeoutExpired as e:
                    # Handle timeout
                    error_output = e.stdout if hasattr(e, 'stdout') and e.stdout else str(e)
                    error_msg = f"Command timed out after {timeout} seconds\n{error_output}"
                    
                    execution_info = {
                        "status": "timeout",
                        "environment": "Container",
                        "host": container_id[:12],
                        "error": str(e)
                    }
                    
                    # Complete with timeout error
                    finish_tool_streaming(tool_name, tool_args, error_msg, call_id, execution_info)
                    
                    # Switch back to idle mode after timeout
                    stop_active_timer()
                    start_idle_timer()
                    # Fallback to local execution on timeout
                    print(color("Container execution timed out. Attempting execution on host instead.", fg="yellow"))
                    return _run_local(command, stdout, timeout, False, None, tool_name, _get_workspace_dir(), args)
                
                except Exception as e:
                    # Handle other errors
                    error_msg = f"Error executing command in container: {str(e)}"
                    
                    execution_info = {
                        "status": "error",
                        "environment": "Container",
                        "host": container_id[:12],
                        "error": str(e)
                    }
                    
                    # Complete with error
                    finish_tool_streaming(tool_name, tool_args, error_msg, call_id, execution_info)
                    
                    # Switch back to idle mode after error
                    stop_active_timer()
                    start_idle_timer()
                    # Fallback to local execution on error
                    print(color("Container execution failed. Attempting execution on host instead.", fg="yellow"))
                    return _run_local(command, stdout, timeout, False, None, tool_name, _get_workspace_dir(), args)

            # Handle Synchronous Execution in Container
            try:
                # Ensure container workspace exists (best effort)
                # Consider moving this to workspace set/container activation
                mkdir_cmd = ["docker", "exec", container_id, "mkdir", "-p", container_workspace] # noqa E501
                subprocess.run(mkdir_cmd, capture_output=True, text=True, check=False, timeout=10) # noqa E501

                # Construct the docker exec command with workspace context
                cmd_list = [
                    "docker", "exec",
                    "-w", container_workspace, # Set working directory
                    container_id,
                    "sh", "-c", command # Execute command via shell
                ]
                result = subprocess.run(
                    cmd_list,
                    capture_output=True,
                    text=True,
                    check=False, # Don't raise exception on non-zero exit
                    timeout=timeout
                )

                output = result.stdout if result.stdout else result.stderr
                output = output.strip() # Clean trailing newline

                # In streaming mode, don't print to stdout to avoid duplication
                # The streaming system will handle the display
                if stdout and not stream:
                    print(f"\033[32m{context_msg} $ {command}\n{output}\033[0m") # noqa E501

                # Check if command failed specifically because container isn't running
                if result.returncode != 0 and "is not running" in result.stderr:
                    print(color(f"{context_msg} Container is not running. Attempting execution on host instead.", fg="yellow")) # noqa E501
                    # Switch back to idle mode before fallback execution
                    stop_active_timer()
                    start_idle_timer()
                    # Fallback to local execution, preserving workspace context
                    return _run_local(command, stdout, timeout, stream, call_id, tool_name, _get_workspace_dir(), args) # noqa E501

                # Switch back to idle mode after command completes
                stop_active_timer()
                start_idle_timer()
                return output # Return combined stdout/stderr

            except subprocess.TimeoutExpired:
                timeout_msg = "Timeout executing command in container."
                if stdout:
                    print(f"\033[33m{context_msg} $ {command}\nTIMEOUT\033[0m") # noqa E501
                    print(color("Attempting execution on host instead.", fg="yellow"))
                # Switch back to idle mode before fallback execution
                stop_active_timer()
                start_idle_timer()
                # Fallback to local execution on timeout
                return _run_local(command, stdout, timeout, stream, call_id, tool_name, _get_workspace_dir(), args) # noqa E501
            except Exception as e:  # pylint: disable=broad-except
                error_msg = f"Error executing command in container: {str(e)}"
                print(color(f"{context_msg} {error_msg}", fg="red"))
                print(color("Attempting execution on host instead.", fg="yellow"))
                # Switch back to idle mode before fallback execution
                stop_active_timer()
                start_idle_timer()
                # Fallback to local execution on other errors
                return _run_local(command, stdout, timeout, stream, call_id, tool_name, _get_workspace_dir(), args) # noqa E501

        # --- CTF Execution ---
        
        if ctf and os.getenv('CTF_INSIDE', "True").lower() == "true":
            # If streaming is enabled and we have a call_id, show streaming UI for CTF too
            if stream:
                # Import the streaming utilities from util
                from cai.util import start_tool_streaming, update_tool_streaming, finish_tool_streaming
                
                # Create args dictionary with standardized format
                tool_args = {
                    "command": cmd_name,
                    "args": cmd_args if cmd_args.strip() else "",
                    "full_command": command,
                    "environment": "CTF",
                    "workspace": os.path.basename(_get_workspace_dir())
                }
                
                # Add refresh rate info for generic_linux_command
                if tool_name == "generic_linux_command":
                    tool_args["refresh_rate"] = 2
                
                # Initialize the streaming session with a consistent call_id format
                call_id = start_tool_streaming(tool_name, tool_args, call_id)
                
                target_dir = _get_workspace_dir()
                #full_command = f"cd '{target_dir}' && {command}"
                full_command = command
                # Update with "executing" status
                update_tool_streaming(
                    tool_name, 
                    tool_args, 
                    f"Executing in CTF environment: {full_command}\n\nWaiting for response...", 
                    call_id
                )
                
                try:
                    # Execute the command and get the output
                    start_time = time.time()
                    output = ctf.get_shell(full_command, timeout=timeout)
                    execution_time = time.time() - start_time
                    
                    # Calculate execution info
                    execution_info = {
                        "status": "completed",
                        "environment": "CTF",
                        "tool_time": execution_time
                    }
                    
                    # Complete the streaming with final output
                    finish_tool_streaming(tool_name, tool_args, output, call_id, execution_info)
                    
                    # Switch back to idle mode after CTF command completes
                    stop_active_timer()
                    start_idle_timer()
                    return output
                    
                except Exception as e:
                    # Handle errors in CTF execution
                    error_msg = f"Error executing CTF command: {str(e)}"
                    execution_info = {
                        "status": "error",
                        "environment": "CTF",
                        "error": str(e)
                    }
                    
                    # Complete the streaming with error output
                    finish_tool_streaming(tool_name, tool_args, error_msg, call_id, execution_info)
                    
                    # Switch back to idle mode after error
                    stop_active_timer()
                    start_idle_timer()
                    return error_msg
            else:
                # Standard non-streaming CTF execution
                result = _run_ctf(ctf, command, stdout, timeout, _get_workspace_dir(), stream)
            
                # Switch back to idle mode after CTF command completes
                stop_active_timer()
                start_idle_timer()
                return result

        # --- SSH Execution ---
        if is_ssh_env:
            # If streaming is enabled, show streaming UI for SSH too
            if stream:
                # Import the streaming utilities from util
                from cai.util import start_tool_streaming, update_tool_streaming, finish_tool_streaming
                
                # Add SSH connection info for display
                ssh_user = os.environ.get('SSH_USER', 'user')
                ssh_host = os.environ.get('SSH_HOST', 'host')
                ssh_connection = f"{ssh_user}@{ssh_host}"
                
                # Create args dictionary with standardized format
                tool_args = {
                    "command": cmd_name,
                    "args": cmd_args if cmd_args.strip() else "",
                    "full_command": command,
                    "ssh_host": ssh_connection,
                    "environment": "SSH"
                }
                
                # Add refresh rate info for generic_linux_command
                if tool_name == "generic_linux_command":
                    tool_args["refresh_rate"] = 2
                
                # Initialize streaming session with a consistent call_id format
                call_id = start_tool_streaming(tool_name, tool_args, call_id)
                
                # Update with "executing" status  
                update_tool_streaming(
                    tool_name, 
                    tool_args, 
                    f"Executing on {ssh_connection}: {command}\n\nWaiting for response...", 
                    call_id
                )
                
                try:
                    # Construct SSH command for execution
                    ssh_pass = os.environ.get('SSH_PASS')
                    if ssh_pass:
                        ssh_cmd_list = ["sshpass", "-p", ssh_pass, "ssh", ssh_connection]
                    else:
                        ssh_cmd_list = ["ssh", ssh_connection]
                    ssh_cmd_list.append(command)
                    
                    # Execute the command and get the output
                    start_time = time.time()
                    result = subprocess.run(
                        ssh_cmd_list,
                        capture_output=True,
                        text=True,
                        check=False,
                        timeout=timeout
                    )
                    execution_time = time.time() - start_time
                    
                    # Get command output
                    output = result.stdout if result.stdout else result.stderr
                    
                    # Add SSH connection info to the output for clarity
                    result_with_info = f"Command executed on {ssh_connection}:\n\n{output}"
                    
                    # Determine status based on return code
                    status = "completed" if result.returncode == 0 else "error"
                    
                    # Calculate execution info
                    execution_info = {
                        "status": status,
                        "environment": "SSH",
                        "host": ssh_connection,
                        "return_code": result.returncode,
                        "tool_time": execution_time
                    }
                    
                    # Complete the streaming with final output
                    finish_tool_streaming(tool_name, tool_args, result_with_info, call_id, execution_info)
                    
                    # Switch back to idle mode after SSH command completes
                    stop_active_timer()
                    start_idle_timer()
                    return output.strip()
                    
                except subprocess.TimeoutExpired as e:
                    # Handle timeout errors
                    error_output = e.stdout if e.stdout else str(e)
                    error_msg = f"Command timed out after {timeout} seconds\n{error_output}"
                    
                    execution_info = {
                        "status": "timeout",
                        "environment": "SSH",
                        "host": ssh_connection,
                        "error": str(e)
                    }
                    
                    # Complete the streaming with timeout error
                    finish_tool_streaming(tool_name, tool_args, error_msg, call_id, execution_info)
                    
                    # Switch back to idle mode after timeout
                    stop_active_timer()
                    start_idle_timer()
                    return error_msg
                    
                except Exception as e:
                    # Handle other errors
                    error_msg = f"Error executing SSH command: {str(e)}"
                    
                    execution_info = {
                        "status": "error",
                        "environment": "SSH",
                        "host": ssh_connection,
                        "error": str(e)
                    }
                    
                    # Complete the streaming with error
                    finish_tool_streaming(tool_name, tool_args, error_msg, call_id, execution_info)
                    
                    # Switch back to idle mode after error
                    stop_active_timer()
                    start_idle_timer()
                    return error_msg
            else:
                # Standard non-streaming SSH execution
                result = _run_ssh(command, stdout, timeout, _get_workspace_dir(), stream)
            
                # Switch back to idle mode after SSH command completes
                stop_active_timer()
                start_idle_timer()
                return result

        # --- Local Execution (Default Fallback) ---
        # Let _run_local handle determining the host workspace
        # Handle Async Session Creation Locally
        # Only create new session if no session_id is provided
        if async_mode and not session_id:
            # create_shell_session uses _get_workspace_dir() when container_id is None
            new_session_id = create_shell_session(command)
            if isinstance(new_session_id, str) and "Failed" in new_session_id:  # Check failure
                # Switch back to idle mode before returning error
                stop_active_timer()
                start_idle_timer()
                return new_session_id
            
            # Display the command that creates the async session
            from cai.util import cli_print_tool_output
            
            # Retrieve the actual workspace dir the session is using
            session = ACTIVE_SESSIONS.get(new_session_id)
            actual_workspace = session.workspace_dir if session else "unknown"
            
            # Create args for display
            session_creation_args = {
                "command": command,
                "args": "",
                "session_id": new_session_id,
                "async_mode": True
            }
            
            # Create execution info
            execution_info = {
                "status": "session_created",
                "environment": "Local",
                "host": os.path.basename(actual_workspace),
                "session_id": new_session_id
            }
            
            # Get initial output if any
            initial_output = ""
            if session:
                time.sleep(0.2)  # Allow session buffer to populate
                initial_output = session.get_new_output(mark_position=True)
            
            # Format the output message
            output_msg = f"Started async session {new_session_id} locally. Use this ID to interact."
            if initial_output:
                output_msg += f"\n\n{initial_output}"
            
            # Display the session creation command and initial output
            cli_print_tool_output(
                tool_name="generic_linux_command",
                args=session_creation_args,
                output=output_msg,
                execution_info=execution_info,
                streaming=False
            )
            
            # For async, switch back to idle mode after session creation
            stop_active_timer()
            start_idle_timer()
            return f"Started async session {new_session_id} locally. Use this ID to interact."

        # Handle Synchronous Execution Locally
        # Pass stream=True if we're streaming to use streaming functionality
        result = _run_local(
            command, 
            stdout, 
            timeout, 
            stream=True, 
            call_id=call_id,
            tool_name=tool_name,
            workspace_dir=_get_workspace_dir(),
            custom_args=args
        )
        
        stop_active_timer()
        start_idle_timer()
        return result
    except Exception as e:
        stop_active_timer()
        start_idle_timer()
        raise
